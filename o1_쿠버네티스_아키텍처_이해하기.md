# Kubernetes 아키텍처 이해하기

## 개요

Kubernetes는 컨테이너화된 애플리케이션의 배포, 확장, 관리를 자동화하는 플랫폼입니다. 여러 서버를 하나의 클러스터로 묶어 단일 시스템처럼 관리할 수 있게 해줍니다.

---

## 클러스터 구조

### 핵심 개념: 여러 서버를 하나로

```
개별 서버 10대가 있다면:
전통 방식: 각 서버에 SSH 접속해서 개별 관리
Kubernetes: 10대를 하나의 클러스터로 묶어서 단일 인터페이스로 관리

┌──────────────────────────────────────────────┐
│           Kubernetes Cluster                  │
│                                               │
│  ┌─────────────┐     ┌──────────────────┐    │
│  │Control Plane│────▶│  Worker Nodes    │    │
│  │  (Master)   │     │                  │    │
│  └─────────────┘     │  Node1 (서버1)   │    │
│                      │  Node2 (서버2)   │    │
│                      │  Node3 (서버3)   │    │
│                      │  ...             │    │
│                      │  Node10 (서버10) │    │
│                      └──────────────────┘    │
└──────────────────────────────────────────────┘

kubectl 명령 하나로 전체 클러스터 관리!
```

### 전체 아키텍처

```
┌─────────────────────────────────────────────────────────┐
│                 Kubernetes Cluster                      │
├─────────────────────┬───────────────────────────────────┤
│   Control Plane     │           Worker Nodes            │
│  (Master Nodes)     │                                   │
│                     │  ┌─────────────┬─────────────┐     │
│  ┌─────────────┐    │  │   Node 1    │   Node 2    │     │
│  │ API Server  │    │  │             │             │     │
│  │ Scheduler   │    │  │ ┌─────────┐ │ ┌─────────┐ │     │
│  │ Controller  │    │  │ │  Pod A  │ │ │  Pod B  │ │     │
│  │ etcd        │    │  │ └─────────┘ │ └─────────┘ │     │
│  └─────────────┘    │  └─────────────┴─────────────┘     │
└─────────────────────┴───────────────────────────────────┘
```

---

## Control Plane (마스터 노드)

클러스터의 두뇌 역할을 하는 관리 컴포넌트들입니다.

### API Server
- 모든 요청을 받는 중앙 관제탑
- kubectl 명령어가 통신하는 대상
- 인증, 권한 검증, 요청 처리

### Scheduler
- 새로 생성된 파드를 어느 노드에 배치할지 결정
- 각 노드의 리소스 상태 확인
- 최적의 노드 선택

### Controller Manager
- 클러스터 상태를 지속적으로 모니터링
- 원하는 상태와 현재 상태가 다르면 조정
- 예: "3개 파드 유지" → 1개 죽으면 자동으로 새로 생성

### etcd
- 클러스터의 모든 데이터를 저장하는 데이터베이스
- 분산 키-값 저장소
- 클러스터의 설정, 상태, 메타데이터 보관

---

## Worker Node

실제 애플리케이션이 실행되는 서버들입니다.

### 노드와 환경 분리

노드(Node)는 물리적 또는 가상의 서버 한 대를 의미합니다. 

- **미니PC 1대 = 1개 노드**
- **AWS EC2 인스턴스 1개 = 1개 노드**

하나의 노드 안에서도 네임스페이스(Namespace)를 사용하면 개발, 스테이징, 운영 환경을 논리적으로 분리할 수 있습니다. 

예를 들어:
- 미니PC 1대(1노드)에서 dev, staging, prod 네임스페이스 생성
- 각 네임스페이스별로 리소스 할당량(CPU, 메모리) 설정
- 완전한 격리가 필요하면 VM이나 실제 여러 서버 사용

### kubelet
- 각 노드에서 실행되는 에이전트
- Control Plane의 지시를 받아 파드 실행
- 파드 상태 모니터링 및 보고

### kube-proxy
- 네트워크 트래픽을 적절한 파드로 전달
- 서비스 추상화 구현
- 로드 밸런싱 제공

### Container Runtime
- 실제 컨테이너를 실행하는 소프트웨어
- Docker, containerd, CRI-O 등

---

## 파드와 노드의 관계

### 하나의 노드에 여러 파드 실행

파드(Pod)는 Kubernetes의 가장 작은 배포 단위입니다. **하나의 노드 안에는 수십~수백 개의 파드가 실행될 수 있습니다.**

```
┌─────────────────────────────────────────┐
│         1개 노드 (미니PC 16GB)           │
├─────────────────────────────────────────┤
│                                         │
│  Pod1      Pod2      Pod3      Pod4     │
│  nginx     mysql     redis    spring    │
│  (256MB)   (2GB)     (512MB)  (1GB)     │
│                                         │
│  Pod5      Pod6      Pod7      Pod8     │
│  grafana   prometheus nextjs  jenkins   │
│  (512MB)   (1GB)     (512MB)  (2GB)     │
│                                         │
│  ... 더 많은 파드 실행 가능 ...          │
└─────────────────────────────────────────┘
```

### 파드 개수 제한 요소

**1. 하드웨어 리소스**
- CPU와 메모리가 허용하는 만큼 실행
- 각 파드가 요구하는 리소스에 따라 결정
- 예: 16GB RAM이면 512MB 파드 약 20-25개 실행 가능

**2. Kubernetes 설정**
- 기본값: 노드당 최대 110개 파드
- K3s는 더 적게 설정될 수 있음
- 필요시 조정 가능

**3. IP 주소**
- 각 파드는 고유 IP 필요
- 서브넷 크기에 따라 제한

### 실제 예시

```bash
# 노드 정보 확인
kubectl describe node minipc

Capacity:
  cpu:     4         # 4 CPU 코어
  memory:  16Gi      # 16GB RAM  
  pods:    110       # 최대 110개 파드 가능

# 현재 실행 중인 파드
kubectl get pods --all-namespaces
NAMESPACE     NAME                     STATUS
kube-system   coredns-xxx              Running
default       nginx-deployment-xxx     Running
default       mysql-0                  Running
dev           spring-app-xxx           Running
# ... 수십 개의 파드들
```

---

## 애플리케이션 배포 흐름

### 1. 코드에서 컨테이너까지

```
Spring Boot 앱 개발
       ↓
Docker 이미지 빌드
       ↓
이미지 레지스트리 푸시
       ↓
Kubernetes에 배포 요청
       ↓
파드로 실행
```

### 2. 배포 프로세스

1. **개발자**: "이 애플리케이션을 3개 실행해주세요"
2. **API Server**: 요청 접수 및 검증
3. **Scheduler**: "Node2가 리소스 여유 있네요. 거기 배치!"
4. **kubelet**: 컨테이너 실행
5. **Controller**: 계속 3개 유지되는지 감시

---

## 네트워킹 구조

### 파드 간 통신

```
Pod A (10.244.1.5) ─────► Pod B (10.244.2.8)
                    직접 통신 가능
```

### 서비스를 통한 접근

```
외부 사용자 → Ingress → Service → Pod들
                         (로드밸런싱)
```

### 서비스 디스커버리

- 파드는 죽었다 살아날 수 있어 IP가 변경됨
- Service는 고정된 이름과 IP 제공
- DNS를 통해 서비스 이름으로 접근 가능

---

## 스토리지 구조

### 임시 스토리지
- 파드와 함께 생성되고 삭제됨
- 컨테이너 간 파일 공유용

### 영구 스토리지
- 파드가 삭제되어도 데이터 유지
- 데이터베이스, 파일 저장소 등에 사용
- PersistentVolume으로 관리

---

## 설정 관리

### ConfigMap
- 애플리케이션 설정 정보 저장
- 환경변수나 설정 파일로 주입

### Secret
- 비밀번호, 토큰, 인증서 등 민감 정보
- Base64 인코딩되어 저장
- 암호화 옵션 제공

---

## 헬스 체크

Kubernetes는 애플리케이션이 정상인지 지속적으로 확인합니다.

### Liveness Probe
- "살아있니?" 체크
- 실패하면 컨테이너 재시작

### Readiness Probe
- "요청 받을 준비됐니?" 체크
- 실패하면 트래픽 차단

### Startup Probe
- "시작 완료됐니?" 체크
- 느린 시작 애플리케이션용

---

## 자동 스케일링

### 수평 스케일링 (HPA)
- CPU/메모리 사용률 기반
- 파드 수를 자동으로 증감
- 예: CPU 70% 넘으면 파드 추가

### 수직 스케일링 (VPA)
- 파드의 리소스 할당량 조정
- 메모리/CPU 요청량 자동 최적화

### 클러스터 스케일링
- 노드 자체를 추가/제거
- 클라우드 환경에서 자동화 가능

---

## 배포 전략

### Rolling Update (기본)
- 하나씩 순차적으로 교체
- 무중단 배포
- 문제 발생 시 롤백 가능

### Recreate
- 모든 파드 중지 후 새 버전 시작
- 다운타임 발생
- 리소스 절약

### Blue-Green
- 새 버전 전체 준비 후 한 번에 전환
- 빠른 롤백 가능
- 리소스 2배 필요

### Canary
- 일부 트래픽만 새 버전으로
- 점진적 배포
- 위험 최소화

---

## 보안 구조

### RBAC
- 역할 기반 접근 제어
- 누가 무엇을 할 수 있는지 정의
- 최소 권한 원칙

### Network Policy
- 파드 간 네트워크 트래픽 제어
- 특정 파드만 통신 허용
- 마이크로세그멘테이션

### Pod Security
- 파드 실행 시 보안 정책 적용
- 루트 권한 제한
- 특권 컨테이너 차단

---

## 모니터링 구조

### 메트릭 수집
```
애플리케이션 → 메트릭 노출 → Prometheus → Grafana
                (/metrics)      (수집)      (시각화)
```

### 로그 수집
```
애플리케이션 → stdout/stderr → 로그 수집기 → 중앙 저장소
                              (Fluentd)    (Elasticsearch)
```

---

## K3s vs K8s 아키텍처 차이

### K8s (풀 버전)
```
여러 컴포넌트가 개별 프로세스로 실행
메모리 사용: 5-10GB
etcd 별도 클러스터
```

### K3s (경량 버전)
```
단일 바이너리로 통합
메모리 사용: 1GB
SQLite 사용 가능
미니PC에 최적화
```

---

## 클러스터 진화 단계

### 시작: 미니PC 단일 노드
```
┌─────────────────────────┐
│  미니PC (All-in-One)    │
│  - Control Plane        │
│  - Worker Node          │
│  - 모든 앱 실행          │
└─────────────────────────┘
```

### 확장: 하이브리드 클러스터
```
┌──────────────┬──────────────┐
│   미니PC     │  클라우드 VM  │
│  (Master)    │  (Workers)   │
└──────────────┴──────────────┘
```

### 프로덕션: 멀티 클러스터
```
개발 클러스터 (미니PC) → GitOps → 운영 클러스터 (Cloud)
```

---

## 멀티클러스터와 GitOps

### 멀티클러스터란?

하나의 Kubernetes 클러스터는 여러 서버(노드)를 묶어서 하나의 시스템처럼 관리하는 단위입니다. 
- 예: 10대의 서버 = 1개의 클러스터

실무에서는 **개발, 스테이징, 운영 환경을 각각 독립된 클러스터로 구성**하는 멀티클러스터 구조를 많이 사용합니다.

### 멀티클러스터가 필요한 이유

**1. 환경 격리**
- 개발 클러스터의 실수가 운영에 영향 없음
- 각 환경별로 다른 설정과 권한 적용

**2. 지역 분산**
- 서울, 부산, 도쿄 등 지역별 클러스터
- 사용자와 가까운 곳에서 서비스 제공

**3. 클라우드 분산**
- AWS, GCP, Azure 등 여러 클라우드 활용
- 특정 클라우드 장애 대비

### GitOps와 ArgoCD

여러 클러스터를 각각 관리하는 것은 복잡합니다. 이를 해결하는 것이 **GitOps** 방식입니다.

**GitOps 동작 방식:**
1. Git 저장소에 설정 파일 저장
2. 개발자가 코드 푸시
3. ArgoCD가 변경 감지
4. 각 클러스터에 자동 배포

**ArgoCD 특징:**
- 개발 환경: 즉시 자동 배포
- 운영 환경: 승인 후 배포
- 배포 이력 Git에 보관
- 문제 시 쉽게 롤백

### 다른 관리 도구들

- **Rancher**: 웹 UI로 멀티클러스터 관리
- **Flux**: 또 다른 GitOps 도구
- **Argo Rollouts**: 고급 배포 전략 지원

이런 도구들로 수십 개의 클러스터도 중앙에서 효율적으로 관리할 수 있습니다.

---

## 요약

Kubernetes는 여러 서버를 하나의 시스템처럼 관리하는 플랫폼입니다. 

**핵심 개념:**
- **클러스터**: 여러 노드(서버)의 집합
- **노드**: 개별 서버 (물리/가상)
- **파드**: 애플리케이션 실행 단위

**주요 특징:**
- Control Plane이 전체를 지휘
- Worker Node에서 실제 애플리케이션 실행
- 자동화된 배포, 스케일링, 복구

가장 중요한 점은 **"여러 대의 서버를 마치 하나의 컴퓨터처럼"** 사용할 수 있다는 것입니다. kubectl 명령어 하나로 수십, 수백 대의 서버를 관리할 수 있습니다.